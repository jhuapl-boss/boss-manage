"""State machine that finds all cuboids in a given channel and enqueues their
S3 object keys in SQS.

Index.FindCuboids

Inputs:
{
    "batch_enqueue_cuboids_step_fcn": "arn:aws:states:...",
    "config": {
      "object_store_config": {
        "id_count_table": "idCount.domain.boss",
        "page_in_lambda_function": "multiLambda-domain-boss",
        "page_out_lambda_function": "multiLambda-domain-boss",
        "cuboid_bucket": "cuboids.domain.boss",
        "s3_index_table": "s3index.domain.boss",
        "id_index_table": "idIndex.domain.boss",
        "s3_flush_queue": "https://queue.amazonaws.com/...",
        "id_index_new_chunk_threshold": 100,
        "index_deadletter_queue": "https://queue.amazonaws.com/...",
        "index_cuboids_keys_queue": "https://queue.amazonaws.com/..."
      },
      "kv_config": {
        "cache_host": "cache.domain.boss",
        "read_timeout": 86400,
        "cache_db": "0"
      },
      "state_config": {
        "cache_state_db": "0",
        "cache_state_host": "cache-state.domain.boss"
      }
    },
    "id_chunk_size": 20,
    "id_cuboid_supervisor_step_fcn": "arn:aws:states:...",
    "id_index_step_fcn": "arn:aws:states:...",
    "index_ids_sqs_url": "...",
    "lookup_key": "..."             # collection&exp&chan&res
    "max_items": int,                   # Max items to retrieve from Dynamo at a time.
    # Number of object ids to include in a single SQS message.
    "num_ids_per_msg": 20,
    "status": {
        "done": bool,
        "lookup_key_n": int,
    },
    "wait_time": 5,
}
"""

version: '1.0'
timeout: 86400      # 1 day

Pass()
    """Init

    Set query_count to 0 before beginning.  A new instance of this step
    function starts when query_count > n.  This avoids the 25K max state
    transition limit when there are huge number of cuboids in a channel.
    """
    result: '$.query_count'
    data:
        0

while '$.status.done' == False:
    """WhileStillTraversingLookupKeyIndex
    """
    Pass()
        """UpdateOperationFieldQuery
        Simply adds the name of the operation so it can be logged properly in 
        the deadletter queue in case of a failure when querying DynamoDB.
        """
        result: '$.operation'
        data: 
            'QueryS3Index'

    Lambda('indexFindCuboidsLambda')
        """QueryS3IndexTable

        index_find_cuboids_lambda.py
        """
        retry [] 60 3 2.0
        catch []: '$.result'
            Lambda('indexWriteFailedLambda')
                """S3ReadFailed
                """
                retry ['KeyError'] 1 0 1.0
                retry [] 10 2 2.0
                catch []: '$.dlqresult'
                    Fail('Exception', 'Failed to write to dead letter queue')
                        """FailedSendingReadFailToDeadLetterQueue
                        """
            Fail('Exception', 'Failed to read from S3 index table')
                """FailedReadingS3Index
                """

    if '$.num_batches' > 0:
        """IfNumBatchesGreaterThan0
        """
        Pass()
            """UpdateOperationFieldSpawnEnqueueSfn
            Simply adds the name of the operation so it can be logged properly in 
            the deadletter queue in case of a failure when querying DynamoDB.
            """
            result: '$.operation'
            data: 
                'Start enqueue cuboids SFN'

        Lambda('startSfnLambda')
            """AsynchEnqueueCuboids

            start_sfn_lambda.py

            Starts Index.EnqueueCuboids - sfn_arn input is set by
            index_find_cuboids_lambda.py.
            """
            retry [
                'StateMachineDoesNotExist', 
                'InvalidArn',
                'KeyError',
                'TypeError'
            ] 1 0 1.0
            retry [] 60 3 2.0
            catch []: '$.result'
                Lambda('indexWriteFailedLambda')
                    """StartEnqueueFailedToDeadletterQueue
                    """
                    retry ['KeyError'] 1 0 1.0
                    retry [] 10 2 2.0
                    catch []: '$.dlqresult'
                        Fail('Exception', 'Failed to write to dead letter queue')
                            """FailedSendingFanoutToDeadLetterQueue
                            """
                Fail('Exception', 'Failed to start fanout enqueuing step function')
                    """FailedStartEnqueue
                    """

    if '$.query_count' > 100:
        """IfQueryCountGreaterThan100

        Stay under state transition max by starting a new instance of this
        step function after 100 queries.
        """
        Pass()
            """UpdateOperationFieldSpawnNewFindCuboidsSfn
            Adds the name of the operation so it can be logged properly in 
            the deadletter queue in case of a failure when querying DynamoDB.

            Also sets sfn_arn to this step function so a new instance can be
            spawned.
            """
            parameters:
                batch_enqueue_cuboids_step_fcn.$: "$.batch_enqueue_cuboids_step_fcn"
                config.$: "$.config"
                fanout_id_writers_step_fcn.$: "$.fanout_id_writers_step_fcn"
                id_chunk_size.$: "$.id_chunk_size"
                id_cuboid_supervisor_step_fcn.$: "$.id_cuboid_supervisor_step_fcn"
                id_index_step_fcn.$: "$.id_index_step_fcn"
                index_ids_sqs_url.$: "$.index_ids_sqs_url"
                lookup_key.$: "$.lookup_key"
                max_items.$: "$.max_items"
                num_ids_per_msg.$: "$.num_ids_per_msg"
                status.$: "$.status"
                wait_time.$: "$.wait_time"

                sfn_arn.$: "$$.StateMachine.Id"
                operation: 'Start new find cuboids SFN'

        Lambda('startSfnLambda')
            """StartNewFindCuboidsSFN

            start_sfn_lambda.py
            """
            retry [
                'StateMachineDoesNotExist', 
                'InvalidArn',
                'KeyError',
                'TypeError'
            ] 1 0 1.0
            retry [] 60 3 2.0
            catch []: '$.result'
                Lambda('indexWriteFailedLambda')
                    """StartNewFindCuboidsToDeadletterQueue
                    """
                    retry ['KeyError'] 1 0 1.0
                    retry [] 10 2 2.0
                    catch []: '$.dlqresult'
                        Fail('Exception', 'Failed to write to dead letter queue')
                            """FailedSendingNewFindCuboidsToDeadLetterQueue
                            """
                Fail('Exception', 'Failed to start fanout enqueuing step function')
                    """FailedStartingNewFindCuboids
                    """
        Success()
            """SentWorkToNewFindCuboidsSFN
            """


Success()
    """FoundAllCuboids
    """
